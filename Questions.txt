****************NOTES******************
Define early stopping in CL approach along with convergence or define early stopping in hyperparameter tuning section

Talk about how and where we apply early stopping -> Also talk about 

In the Mann-Whitney U section talk about hypothesis testing and what we are testing
Here we can state our null and alternative hypothesis.

Look at the train loss as well.
************************QUESTIONS****************************
Early stopping did not work great to actually stop the training (It works, but it is not optimised.)
    - Evidence suggests that less epochs can be used, but we did not test this.
    - Future work

Bad training accuracy, but good test accuracy, Good training accuracy, but bad test accuracy
    - Bad dataset split?
    - Overfitting? 

Why is the performance on AlexNet better than ResNet?
    - Gets convoluted?
    - Overfits?
    - Not enough information to learn?

 Talk about losss as well

**List software -> Have a public github + upload datasets on Kaggle

Also show some type of graph ... maybe a heatmap? -> As an extension on Monday.


***************************HINTS****************************
Graphs to draw + Stats to compute:
    - Convergence plots that include the std (plot line with deviation)
        - Baseline vs Proposed
    - Line graphs for convergence
    - Tables for final best performance
    - Box and whisker -> for outliers?
    - Graphs that give additional insights 

    - Hypothesis testing -> Will coxin rank sum test
        null -> Samples from same distro
        what we want-> Smaples from different distro
        -> Calculate p values

    - Add some discussion points about how it was ordered.
        - After 5 epochs 

Networks to use:
    - ResNet and AlexNet
    - The goal is to show the performance due to simple objects
